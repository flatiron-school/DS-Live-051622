{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Applications in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://www.analyticsvidhya.com/blog/2019/07/10-applications-linear-algebra-data-science/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seaborn import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "gems = load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors and Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of linear algebra, a single number is a 0-dimensional entity called a **scalar**. But it is often useful to have data in the form of a 1-dimensional object called a **vector**, which can be thought of as a list of scalars. Think here of a `pandas` Series. And in addition to the values that compose the vector, we can characterize the vector as a whole as having a **magnitude** and a **direction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars: 2, 2.5, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors: x = [1,2,3]\n",
    "    x_1 = 1\n",
    "    x_2 = 2\n",
    "    x_3 = 3\n",
    "    \n",
    "[1\n",
    " 2\n",
    " 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot([0, 3], [0, 4], 'b')\n",
    "ax.vlines(1, ymin=0, ymax=4/3)\n",
    "ax.scatter(0, 0, s=30)\n",
    "\n",
    "# arrowhead!\n",
    "ax.vlines(3, ymin=3.7, ymax=4, colors='b')\n",
    "ax.hlines(4, xmin=2.8, xmax=3, colors='b')\n",
    "ax.annotate('$\\phi$', xy=(1.1, 0.5))\n",
    "ax.annotate('|v| = 5', xy=(0.9, 2.3))\n",
    "ax.set_xlim(right=5)\n",
    "ax.set_ylim(top=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been working all along with arrays and data frames that have a tabular structure of rows and columns. Such a 2-dimensional structure of numerical elements is known in linear algebra as a **matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23, 'Ideal', 'E', 'SI2', 61.5, 55.0, 326, 3.95, 3.98, 2.43],\n",
       "       [0.21, 'Premium', 'E', 'SI1', 59.8, 61.0, 326, 3.89, 3.84, 2.31],\n",
       "       [0.23, 'Good', 'E', 'VS1', 56.9, 65.0, 327, 4.05, 4.07, 2.31],\n",
       "       [0.29, 'Premium', 'I', 'VS2', 62.4, 58.0, 334, 4.2, 4.23, 2.63],\n",
       "       [0.31, 'Good', 'J', 'SI2', 63.3, 58.0, 335, 4.34, 4.35, 2.75]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gems.head().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want 3- or even higher-dimensional objects. Think for example of a digital image where we record the red, green, and blue values *for each pixel in the 2d array*. The linear algebraic abstraction we need for such an object is called a **tensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.72900717, 0.77127035, 0.07404465, 0.35846573, 0.11586906],\n",
       "        [0.86310343, 0.62329813, 0.33089802, 0.06355835, 0.31098232],\n",
       "        [0.32518332, 0.72960618, 0.63755747, 0.88721274, 0.47221493],\n",
       "        [0.11959425, 0.71324479, 0.76078505, 0.5612772 , 0.77096718],\n",
       "        [0.4937956 , 0.52273283, 0.42754102, 0.02541913, 0.10789143]],\n",
       "\n",
       "       [[0.03142919, 0.63641041, 0.31435598, 0.50857069, 0.90756647],\n",
       "        [0.24929223, 0.41038292, 0.75555114, 0.22879817, 0.07697991],\n",
       "        [0.28975145, 0.16122129, 0.92969765, 0.80812038, 0.63340376],\n",
       "        [0.87146059, 0.80367208, 0.18657006, 0.892559  , 0.53934224],\n",
       "        [0.80744016, 0.8960913 , 0.31800347, 0.11005192, 0.22793516]],\n",
       "\n",
       "       [[0.42710779, 0.81801477, 0.86073058, 0.00695213, 0.5107473 ],\n",
       "        [0.417411  , 0.22210781, 0.11986537, 0.33761517, 0.9429097 ],\n",
       "        [0.32320293, 0.51879062, 0.70301896, 0.3636296 , 0.97178208],\n",
       "        [0.96244729, 0.2517823 , 0.49724851, 0.30087831, 0.28484049],\n",
       "        [0.03688695, 0.60956433, 0.50267902, 0.05147875, 0.27864646]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4, 1. , 0.7, 0.6, 0.2],\n",
       "        [0.2, 0.1, 0.9, 0.6, 0.7],\n",
       "        [0. , 1. , 0.8, 0.2, 0.2],\n",
       "        [0.2, 0.3, 0.5, 0.4, 0.3],\n",
       "        [0.6, 0.1, 0.3, 0.4, 0.5]],\n",
       "\n",
       "       [[0.8, 0.2, 0.5, 0.6, 0. ],\n",
       "        [0.6, 0.2, 0.1, 0.9, 1. ],\n",
       "        [0.8, 0.3, 0.1, 0.7, 0.4],\n",
       "        [0.1, 0.5, 0. , 0.9, 0.3],\n",
       "        [0.7, 0.3, 0.5, 0.5, 0.2]],\n",
       "\n",
       "       [[1. , 0.8, 0.9, 0.9, 0.6],\n",
       "        [0.9, 0.1, 0.2, 0. , 0.3],\n",
       "        [0.4, 0.3, 0.8, 0.4, 0.3],\n",
       "        [0.5, 0.1, 0.8, 0.1, 1. ],\n",
       "        [0.8, 0.2, 0. , 0.8, 0.7]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42) #setting a random seed\n",
    "\n",
    "#generate random values for a numpy array of shape (3,5,5), and round those values to 1 digit\n",
    "tensor = np.round(np.random.rand(3, 5, 5), 1)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[2][3][2]  #access the (0,0,0)th element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.round(np.random.rand(2, 3, 2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7, 0.8, 0.2],\n",
       "       [0.7, 0.4, 0.6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.round(np.random.rand(2,3),1)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices can be added and multiplied, and there are other distinctive operations on matrices that are often useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Matrix Addition</b>: Click for Illustration</summary>\n",
    "$\\begin{bmatrix}\n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{11} + b_{11} & a_{12} + b_{12} \\\\\n",
    "a_{21} + b_{21} & a_{22} + b_{22}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 4],\n",
       "       [8, 5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#return a numpy array of shape (2,2) with random integers from 1 inclusive to 11 exclusive\n",
    "my_matrix1 = np.random.randint(low=1, high=11, size=(2, 2))\n",
    "my_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [ 3,  7]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix2 = np.random.randint(low=1, high=11, size=(2, 2))\n",
    "my_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 14],\n",
       "       [11, 12]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform matrix addition with our two matrices\n",
    "my_matrix1 + my_matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Matrix Multiplication</b>: Click for Illustration</summary>\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "b_{1,1} & b_{1,2} \\\\\n",
    "b_{2,1} & b_{2,2}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "a_{1,1}\\times b_{1,1} + a_{1,2}\\times b_{2,1} & a_{1,1}\\times b_{1,2} + a_{1,2}\\times b_{2,2} \\\\\n",
    "a_{2,1}\\times b_{1,1} + a_{2,2}\\times b_{2,1} & a_{2,1}\\times b_{1,2} + a_{2,2}\\times b_{2,2}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61,  98],\n",
       "       [ 71, 115]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform matrix multiplication with our two matrices\n",
    "my_matrix1.dot(my_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61,  98],\n",
       "       [ 71, 115]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(my_matrix1, my_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[129,  78],\n",
       "       [ 77,  47]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(my_matrix2, my_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A @ B != B @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 * 7 = 7 * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many times when we need to measure distances. For example, many modeling algorithms rely on a notion of **similarity** between data points. But we have already seen how distance is used to construct a linear model: Choose the betas that minimize the sum of squared **distances** between true and predicted $y$-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider this distance for *all* data points at once: We can think of that as a vector: $\\vec{(y_i - \\hat{y_i})^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in fact there are multiple ways to measure the magnitude of a vector. Typically, we are thinking of Euclidean spaces and so use the **L2 norm** to measure the magnitude of a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec = np.array([3, 4, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(3**2 + 4**2 + 12**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use numpy method to get magnitude of a vector\n",
    "np.linalg.norm(my_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are other norms we can use. In general, the **$n$-norm** will calculate $(x_1^n + ... + x_m^n)^{\\frac{1}{n}}$ for a vector $\\vec{x_i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.207054953820636"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use numpy method to get the n-norm\n",
    "np.linalg.norm(my_vec, ord=3) #in this case we are calculating the 3-norm\n",
    "\n",
    "#(3^3 + 4^3 + 12^3) ^ (1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can express covariance and correlation matrices as linear-algebraic transformations:\n",
    "\n",
    "For a centered data matrix $M$:\n",
    "- $cov(M) = \\frac{1}{n-1}M^TM$, where $n$ is the number of observations.\n",
    "\n",
    "A centered data matrix is one whose column means are all 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This equation makes use of the **transpose** of a matrix $M$, $M^T$, which is the matrix that results from swapping the rows and columns of $M$. You can also think of this as a *reflection* of the elements of $M$ about the main diagonal of $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 4],\n",
       "       [8, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 8],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the transpose of my matrix\n",
    "my_matrix_transposed = my_matrix1.T\n",
    "my_matrix_transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's illustrate this equation. Suppose we have ten observations (rows) for each of three variables (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37454012, 0.95071431, 0.73199394],\n",
       "       [0.59865848, 0.15601864, 0.15599452],\n",
       "       [0.05808361, 0.86617615, 0.60111501],\n",
       "       [0.70807258, 0.02058449, 0.96990985],\n",
       "       [0.83244264, 0.21233911, 0.18182497],\n",
       "       [0.18340451, 0.30424224, 0.52475643],\n",
       "       [0.43194502, 0.29122914, 0.61185289],\n",
       "       [0.13949386, 0.29214465, 0.36636184],\n",
       "       [0.45606998, 0.78517596, 0.19967378],\n",
       "       [0.51423444, 0.59241457, 0.04645041]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "mat_1 = np.random.rand(10, 3)\n",
    "mat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_1_centered = mat_1 - np.mean(mat_1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05515441,  0.50361038,  0.29300058],\n",
       "       [ 0.16896396, -0.29108529, -0.28299885],\n",
       "       [-0.37161091,  0.41907222,  0.16212165],\n",
       "       [ 0.27837805, -0.42651943,  0.53091649],\n",
       "       [ 0.40274812, -0.23476482, -0.2571684 ],\n",
       "       [-0.24629001, -0.14286168,  0.08576307],\n",
       "       [ 0.00225049, -0.15587479,  0.17285953],\n",
       "       [-0.29020066, -0.15495928, -0.07263152],\n",
       "       [ 0.02637546,  0.33807204, -0.23931958],\n",
       "       [ 0.08453991,  0.14531064, -0.39254295]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_1_centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06245653, -0.03833006, -0.01323947],\n",
       "       [-0.03833006,  0.10612618, -0.00378735],\n",
       "       [-0.01323947, -0.00378735,  0.08823377]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_1_centered.T.dot(mat_1_centered) / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06245653, -0.03833006, -0.01323947],\n",
       "       [-0.03833006,  0.10612618, -0.00378735],\n",
       "       [-0.01323947, -0.00378735,  0.08823377]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use numnpy to obtain the covariance matrix\n",
    "cov = np.cov(mat_1, rowvar = False)\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the correlation matrix by hand\n",
    "stds = np.sqrt(np.diag(cov))\n",
    "np.diag(stds**-1).dot(cov).dot(np.diag(stds**-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.4708031 , -0.17834632],\n",
       "       [-0.4708031 ,  1.        , -0.03913878],\n",
       "       [-0.17834632, -0.03913878,  1.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use numpy to obtain the correlation matrix\n",
    "corr = np.corrcoef(mat_1, rowvar=False)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that it is difficult for us to interpret covariances because covariance values are very dependent on the specific data values, hence why we look at **correlation, which gives us the covariance on a standardized scale**. If we are looking at the covariance between variables $X_1$ and $X_2$, the correlation is simply standardizing the covariance by the standard deviations of $X_1$ and $X_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Bonus: Correlation Matrices</summary>\n",
    "    To calculate a correlation matrix, we can multiply the covariance matrix on both sides by a diagonal matrix of the reciprocals of the standard deviations of the columns. [Source](https://blogs.sas.com/content/iml/2010/12/10/converting-between-correlation-and-covariance-matrices.html)\n",
    "\n",
    "<code>stds = np.sqrt(np.diag(cov))\n",
    "np.diag(stds\\*\\*-1).dot(cov).dot(np.diag(stds\\*\\*-1))\n",
    "np.corrcoef(mat_1, rowvar=False)\n",
    "</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving a System of Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In elementary algebra we start by solving one equation for one unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image from mathelp.org](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSnrLW6J0FYge6zWDKqRrAtWx4Jf0HkhMiwHQ&usqp=CAU) source: mathelp.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear algebra gives us the tools to solve many equations simultaneously. Suppose we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 -2 3] dot product [x_1 x_2 x_3] = 1 * x_1 + -2 * x_2 + 3 * x_3 = x_1 - 2x_2 + 3x_3 = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{align}\n",
    " x_1 - 2x_2 + 3x_3 &= 9 \\\\\n",
    " 2x_1 - 5x_2 + 10x_3 &= 4 \\\\\n",
    " 6x_3 &= 0 \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write these equations as a single matrix equation:\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "    1 & -2 & 3 \\\\\n",
    "    2 & -5 & 10 \\\\\n",
    "    0 & 0 & 6\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "    x_1 \\\\\n",
    "    x_2 \\\\\n",
    "    x_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "    9 \\\\\n",
    "    4 \\\\\n",
    "    0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or: $A\\vec{x} = \\vec{b}$, where\n",
    "\n",
    "- $A = \\begin{bmatrix} \n",
    "    1 & -2 & 3 \\\\\n",
    "    2 & -5 & 10 \\\\\n",
    "    0 & 0 & 6\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $\\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}$, and\n",
    "\n",
    "- $\\vec{b} = \\begin{bmatrix} 9 \\\\ 4 \\\\ 0 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we're solving for a *vector* of unknowns. To solve $A\\vec{x} = \\vec{b}$ for $x$, we multiply both sides of the equation by **$A^{-1}$, the inverse of $A$**:\n",
    "\n",
    "$A^{-1}A\\vec{x} = \\vec{x} = A^{-1}b$\n",
    "\n",
    "In just the way that multiplying a scalar by its multiplicative inverse produces 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A A^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "36 * 1 = 36, 37 * 1 = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42 * (1/42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42 * 42**-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so multiplying a matrix by its matrix inverse produces $I$, the **identity matrix**, a square matrix with 1's down the main diagonal and 0's everywhere else.\n",
    "\n",
    "> $$\\begin{align}\n",
    "    I_3 &= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} \\\\\n",
    "    \\\\\n",
    "    I_5 &= \\begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "                           0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "                           0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "                           0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "                           0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "                           0 & 0 & 0 & 0 & 0 & 1 \\\\                           \n",
    "            \\end{bmatrix}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse and identity matrices have important properties:\n",
    "\n",
    "- $IA = A$\n",
    "- $AI = A$\n",
    "- $AA^{-1} = I$\n",
    "- $A^{-1}A = I$\n",
    "- $I\\vec{x} = \\vec{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 1 -2  3]\n",
      " [ 2 -5 10]\n",
      " [ 0  0  6]]\n",
      "\n",
      "b:\n",
      "[[9]\n",
      " [4]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, -2,  3],\n",
    "    [2, -5, 10],\n",
    "    [0,  0,  6]\n",
    "])\n",
    "\n",
    "b = np.array([9, 4, 0]).reshape(3, 1)\n",
    "\n",
    "print('A:')\n",
    "print(A)\n",
    "print()\n",
    "print('b:')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.         -2.          0.83333333]\n",
      " [ 2.         -1.          0.66666667]\n",
      " [ 0.          0.          0.16666667]]\n",
      "x1 = 37.0, x2 = 14.0, x3 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Find the inverse\n",
    "\n",
    "A_inv = np.linalg.inv(A)\n",
    "print(A_inv)\n",
    "\n",
    "# Getting the solution\n",
    "\n",
    "x1, x2, x3 = A_inv @ b   #the @ operator performs matrix multiplication\n",
    "print(f\"x1 = {x1[0]}, x2 = {x2[0]}, x3 = {x3[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy will default to representing it as a vertical vector\n",
    "np.array([x1, x2, x3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.],\n",
       "       [4.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.dot(np.array([x1, x2, x3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve It Faster with NumPy's `linalg.solve()`\n",
    "\n",
    "NumPy's ```linalg``` module has a ```.solve()``` method that you can use to solve a system of linear equations!\n",
    "\n",
    "In particular, it will solve for the vector $\\vec{x}$ in the equation $A\\vec{x} = b$. You should know that, \"under the hood\", the ```.solve()``` method does NOT compute the inverse matrix $A^{-1}$. This is largely because of the enormous expense of directly computing a matrix inverse, which takes $\\mathcal{O}(n^3)$ time.\n",
    "\n",
    "Check out [this discussion](https://stackoverflow.com/questions/31256252/why-does-numpy-linalg-solve-offer-more-precise-matrix-inversions-than-numpy-li) on stackoverflow for more on the differences between using `.solve()` and `.inv()`.\n",
    "\n",
    "And check out the documentation for ```.solve()``` [here](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [14.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the .solve() method to solve this system of equations\n",
    "\n",
    "A = np.array([\n",
    "    [1, -2,  3],\n",
    "    [2, -5, 10],\n",
    "    [0,  0,  6]\n",
    "])\n",
    "\n",
    "b = np.array([9, 4, 0]).reshape(3, 1)\n",
    "\n",
    "#Use the solve method to solve this system of equations\n",
    "np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we could just solve our matrix equation by calculating the inverse of our matrix $A$ and then multiplying by $b$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.],\n",
       "       [14.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(A).dot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the time difference is striking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.8 µs ± 3.41 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.linalg.inv(A).dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.43 µs ± 14.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for a (tiny!) 3x3 matrix, the cost of computing the inverse directly is evident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a typical dataset and the associated multiple linear regression problem. We have many observations (rows), each of which consists of a set of values both for the predictors (columns, i.e. the independent variables) and for the target (the dependent variable).\n",
    "\n",
    "For the equation $A\\vec{x} = \\vec{c}$, we can think of the values of the independent variables (i.e. the data matrix, \"X\") as our matrix $A$ of coefficients and of the values of the dependent variable (i.e. the target, \"y\") as our output vector $\\vec{c}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task here is, in effect, to solve for $\\vec{\\beta}$, where we have that $A\\vec{\\beta} = \\vec{c}$, except in general we'll have more rows than columns. But more rows than columns means more equations than unknowns, which means that in general **there is no solution**. This is why instead we go for an optimization--in our case, a best-fit line. So we have $A\\vec{\\beta}\\approx\\vec{c}$.\n",
    "\n",
    "Using $a$ for our independent variables and $c$ for our dependent variable, we have:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta_1\\begin{bmatrix}\n",
    "a_{1,1} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "a_{m,1}\n",
    "\\end{bmatrix} +\n",
    "... + \\beta_n\\begin{bmatrix}\n",
    "a_{1,n} \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    ". \\\\\n",
    "a_{m,n}\n",
    "\\end{bmatrix} \\approx \\begin{bmatrix}\n",
    "c_1 \\\\\n",
    ".  \\\\\n",
    ".  \\\\\n",
    ".  \\\\\n",
    "c_m\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overdetermined system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X B ~= y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra Solves the Best-Fit Line Problem\n",
    "\n",
    "If we have a matrix of predictors $X$ and a target column $y$, we can express $\\vec{\\beta}$, the vectorized parameters of the best-fit line, as  follows:\n",
    "\n",
    "$\\large\\vec{\\beta} = (X^TX)^{-1}X^Ty$.\n",
    "\n",
    "$(X^TX)^{-1}X^T$ is sometimes called the *pseudo-inverse* of $X$.\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49671415,  1.53658231],\n",
       "       [-0.1382643 ,  1.53427025],\n",
       "       [ 0.64768854,  2.24196227],\n",
       "       [ 1.52302986,  0.08671976],\n",
       "       [-0.23415337,  0.27508217],\n",
       "       [-0.23413696,  1.43771247],\n",
       "       [ 1.57921282,  0.98716888],\n",
       "       [ 0.76743473,  2.31424733],\n",
       "       [-0.46947439,  1.09197592],\n",
       "       [ 0.54256004,  0.5876963 ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "preds = np.array(list(zip(np.random.normal(size=10),\n",
    "                          np.array(np.random.normal(size=10, loc=2)))))\n",
    "target = np.array(np.random.exponential(size=10))\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45404034, 0.2599216 ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(preds.T.dot(preds)).dot(preds.T).dot(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45404034, 0.2599216 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression(fit_intercept=False).fit(preds, target).coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Taste of What's Coming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues, Singular Values, Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to express a matrix as a **product** of other matrices. Sometimes the gain is only in computational efficiency, but there are also certain factorizations or **decompositions** that are useful in other ways.\n",
    "\n",
    "An **eigendecomposition** reduces a matrix to a collection of vectors that capture the *linear* action of the matrix. Selecting the vectors that produce the largest such linear transformations is the idea behind **principal component analysis**, which is useful for reducing high-dimensional datasets to lower-dimensional problems.\n",
    "\n",
    "Eigendecompositions are possibly only for square matrices; a **singular value decomposition** is a more fundamental matrix factorization that can be applied to any matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do recommendation engines work?\n",
    "\n",
    "Imagine representing your interests (film genres, book subjects, music styles) as a **vector**: larger numbers represent larger preferences. Now do this for multiple people. Now we can think of comparing these vectors directly or against some target such as whether a given product/service was used/bought/watched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When our data is **unlabeled** we have a problem in **unsupervised learning**. One major strategy for this type of problem is to impose a *similarity* metric on our data points. Similarity between data points is measured as some function of the **(vector) distance** between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One similarity metric for vectors is **cosine similarity**, which computes the *cosine of the angle between them*. Note that this is always well-defined for non-zero vectors since any two vectors determine a plane (in which the angle can be measured)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "We saw already above the idea of representing a digital image as a **tensor** of values that encode facts about each pixel in the digitization.\n",
    "\n",
    "**Neural networks** are good for working with tensors of high dimension. Such objects often need to be manipulated into different shapes, and the `.reshape()` method is great for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.reshape(5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.reshape(1, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: Matrix Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many transformations of *products* of matrices can be expressed in terms of the transformation applied to the factors *in reverse order*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(AB)^T = B^TA^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(low=1, high=11, size=(10, 2))\n",
    "B = np.random.randint(low=1, high=11, size=(2, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A.dot(B)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.T.dot(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(AB)^{-1} = B^{-1}A^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(low=1, high=11, size=(3, 3))\n",
    "B = np.random.randint(low=1, high=11, size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(A.dot(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linalg.inv(B).dot(np.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: The Determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determinant\n",
    "\n",
    "The **determinant** of a square matrix $M$, $|M|$, represents the area (or, in higher dimensions, the volume) of the parallelogram (parallelepiped) formed by the rows or columns of $M$. And it is also related to the inverse of $M$.\n",
    "\n",
    "For a 2x2 matrix $\\begin{bmatrix} a & b \\\\ c & d\\end{bmatrix}$, the determinant is equal to $ad - bc$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_matrix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(my_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = my_matrix1[0][0]\n",
    "d = my_matrix1[1][1]\n",
    "b = my_matrix1[0][1]\n",
    "c = my_matrix1[1][0]\n",
    "\n",
    "a*d - b*c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
